# xmake onnxruntime  

## models

⏰:model and files in build_files, put in with exe file.

you may run .sh , for fun.

## yolov5

### compile 

by xmake

### run

⏰:put "libonnxruntime.so" and "libonnxruntime.so.1.17.0" with exe file.

```sh
./yolov5_detect --model_path models/yolov5m.onnx --image images/bus.jpg --class_names models/coco.names --gpu
```

### References

https://github.com/itsnine/yolov5-onnxruntime

https://github.com/junchao98/yolov5-onnxruntime

YOLO v5 repo: https://github.com/ultralytics/yolov5

YOLOv5 Runtime Stack repo: https://github.com/zhiqwang/yolov5-rt-stack

ONNXRuntime Inference examples: https://github.com/microsoft/onnxruntime-inference-examples

## yolov8

### References for yolov8

YOLO v8 repo: https://github.com/ultralytics/yolov8

