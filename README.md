# xmake onnxruntime  

## models

‚è∞:model and files in build_files, put in with exe file.

you may run .sh , for fun.

## yolov5

### compile 

by xmake

### run

‚è∞:put "libonnxruntime.so" and "libonnxruntime.so.1.17.0" with exe file.

```sh
./yolov5_detect --model_path models/yolov5m.onnx --image images/bus.jpg --class_names models/coco.names --gpu
```

### References

https://github.com/itsnine/yolov5-onnxruntime

https://github.com/junchao98/yolov5-onnxruntime

YOLO v5 repo: https://github.com/ultralytics/yolov5

YOLOv5 Runtime Stack repo: https://github.com/zhiqwang/yolov5-rt-stack

ONNXRuntime Inference examples: https://github.com/microsoft/onnxruntime-inference-examples

## yolov8

### References for yolov8

YOLO v8 repo: https://github.com/ultralytics/yolov8

## yolov8_2 

### References for yolov8
 
 fork from:

  https://github.com/UNeedCryDear/yolov8-opencv-onnxruntime-cpp


## yolov8_3_pose 

forked from :

https://github.com/FourierMourier/yolov8-onnx-cpp
  

 üòÑ 